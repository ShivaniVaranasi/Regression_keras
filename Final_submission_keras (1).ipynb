{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom sklearn.metrics import mean_squared_error\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","execution_count":71,"outputs":[{"output_type":"stream","text":"/kaggle/input/concrete-data/concrete_data.csv\n","name":"stdout"}]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"import tensorflow.keras","execution_count":3,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/concrete-data/concrete_data.csv\")","execution_count":79,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.head()","execution_count":80,"outputs":[{"output_type":"execute_result","execution_count":80,"data":{"text/plain":"   Cement  Blast Furnace Slag  Fly Ash  Water  Superplasticizer  \\\n0   540.0                 0.0      0.0  162.0               2.5   \n1   540.0                 0.0      0.0  162.0               2.5   \n2   332.5               142.5      0.0  228.0               0.0   \n3   332.5               142.5      0.0  228.0               0.0   \n4   198.6               132.4      0.0  192.0               0.0   \n\n   Coarse Aggregate  Fine Aggregate  Age  Strength  \n0            1040.0           676.0   28     79.99  \n1            1055.0           676.0   28     61.89  \n2             932.0           594.0  270     40.27  \n3             932.0           594.0  365     41.05  \n4             978.4           825.5  360     44.30  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n      <th>Strength</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1040.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>79.99</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>540.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>162.0</td>\n      <td>2.5</td>\n      <td>1055.0</td>\n      <td>676.0</td>\n      <td>28</td>\n      <td>61.89</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>270</td>\n      <td>40.27</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>332.5</td>\n      <td>142.5</td>\n      <td>0.0</td>\n      <td>228.0</td>\n      <td>0.0</td>\n      <td>932.0</td>\n      <td>594.0</td>\n      <td>365</td>\n      <td>41.05</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>198.6</td>\n      <td>132.4</td>\n      <td>0.0</td>\n      <td>192.0</td>\n      <td>0.0</td>\n      <td>978.4</td>\n      <td>825.5</td>\n      <td>360</td>\n      <td>44.30</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1=df.iloc[:,:-1]\nY1=df.iloc[:,-1]","execution_count":81,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"df.isnull().sum()","execution_count":82,"outputs":[{"output_type":"execute_result","execution_count":82,"data":{"text/plain":"Cement                0\nBlast Furnace Slag    0\nFly Ash               0\nWater                 0\nSuperplasticizer      0\nCoarse Aggregate      0\nFine Aggregate        0\nAge                   0\nStrength              0\ndtype: int64"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from keras.models import Sequential\nfrom keras.layers import Dense","execution_count":83,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# define regression model\ndef regression_model():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(X1_train.shape[1],)))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","execution_count":84,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model=regression_model()","execution_count":85,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model\nresults=[]\nfor i in range(50):\n    X1_train,X1_test,y1_train,y1_test=train_test_split(X1,Y1,test_size=0.3,random_state=42)\n    model.fit(X1_train, y1_train, validation_split=0.3, epochs=50, verbose=0)\n    y_pred=model.predict(X1_test)\n    results.append(mean_squared_error(y1_test, y_pred))\n","execution_count":86,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics\nprint(\"Results mean\"+str(statistics.mean(results)))","execution_count":95,"outputs":[{"output_type":"stream","text":"Results mean84.47355517148709\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Results std\"+str(statistics.stdev(results)))","execution_count":96,"outputs":[{"output_type":"stream","text":"Results std85.58664030888238\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X1_norm=(X1-X1.mean())/X1.std()\nX1_norm.head()","execution_count":97,"outputs":[{"output_type":"execute_result","execution_count":97,"data":{"text/plain":"     Cement  Blast Furnace Slag   Fly Ash     Water  Superplasticizer  \\\n0  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n1  2.476712           -0.856472 -0.846733 -0.916319         -0.620147   \n2  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n3  0.491187            0.795140 -0.846733  2.174405         -1.038638   \n4 -0.790075            0.678079 -0.846733  0.488555         -1.038638   \n\n   Coarse Aggregate  Fine Aggregate       Age  \n0          0.862735       -1.217079 -0.279597  \n1          1.055651       -1.217079 -0.279597  \n2         -0.526262       -2.239829  3.551340  \n3         -0.526262       -2.239829  5.055221  \n4          0.070492        0.647569  4.976069  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cement</th>\n      <th>Blast Furnace Slag</th>\n      <th>Fly Ash</th>\n      <th>Water</th>\n      <th>Superplasticizer</th>\n      <th>Coarse Aggregate</th>\n      <th>Fine Aggregate</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>0.862735</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2.476712</td>\n      <td>-0.856472</td>\n      <td>-0.846733</td>\n      <td>-0.916319</td>\n      <td>-0.620147</td>\n      <td>1.055651</td>\n      <td>-1.217079</td>\n      <td>-0.279597</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>3.551340</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.491187</td>\n      <td>0.795140</td>\n      <td>-0.846733</td>\n      <td>2.174405</td>\n      <td>-1.038638</td>\n      <td>-0.526262</td>\n      <td>-2.239829</td>\n      <td>5.055221</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-0.790075</td>\n      <td>0.678079</td>\n      <td>-0.846733</td>\n      <td>0.488555</td>\n      <td>-1.038638</td>\n      <td>0.070492</td>\n      <td>0.647569</td>\n      <td>4.976069</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"X2_train,X2_test,y2_train,y2_test=train_test_split(X1_norm,Y1,test_size=0.3,random_state=21)","execution_count":51,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Results B - with normalized input"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model\nresults_b=[]\nfor i in range(50):\n    X2_train,X2_test,y2_train,y2_test=train_test_split(X1_norm,Y1,test_size=0.3,random_state=42)\n    model.fit(X2_train, y2_train, validation_split=0.3, epochs=50, verbose=0)\n    y_pred=model.predict(X2_test)\n    results_b.append(mean_squared_error(y2_test, y_pred))\n","execution_count":98,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics\nprint(\"Results mean\"+str(statistics.mean(results_b)))","execution_count":99,"outputs":[{"output_type":"stream","text":"Results mean63.84740394698038\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Results std\"+str(statistics.stdev(results_b)))","execution_count":100,"outputs":[{"output_type":"stream","text":"Results std54.65455494237985\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"100 epochs Part c"},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model\nresults_c=[]\nfor i in range(50):\n    X2_train,X2_test,y2_train,y2_test=train_test_split(X1_norm,Y1,test_size=0.3,random_state=42)\n    model.fit(X2_train, y2_train, validation_split=0.3, epochs=100, verbose=0)\n    y_pred=model.predict(X2_test)\n    results_c.append(mean_squared_error(y2_test, y_pred))\n","execution_count":101,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics\nprint(\"Results mean\"+str(statistics.mean(results_c)))","execution_count":102,"outputs":[{"output_type":"stream","text":"Results mean41.93833966398077\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Results std\"+str(statistics.stdev(results_c)))","execution_count":103,"outputs":[{"output_type":"stream","text":"Results std0.5226906166465041\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Part d (10 neurons and 3 hidden layers)"},{"metadata":{"trusted":true},"cell_type":"code","source":"# define regression model\ndef regression_model_d():\n    # create model\n    model = Sequential()\n    model.add(Dense(10, activation='relu', input_shape=(X1_train.shape[1],)))\n    model.add(Dense(10, activation='relu', input_shape=(X1_train.shape[1],)))\n    model.add(Dense(10, activation='relu', input_shape=(X1_train.shape[1],)))\n    model.add(Dense(1))\n    \n    # compile model\n    model.compile(optimizer='adam', loss='mean_squared_error')\n    return model","execution_count":106,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_d=regression_model_d()","execution_count":107,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# fit the model\nresults_d=[]\nfor i in range(50):\n    X2_train,X2_test,y2_train,y2_test=train_test_split(X1_norm,Y1,test_size=0.3,random_state=42)\n    model.fit(X2_train, y2_train, validation_split=0.3, epochs=50, verbose=0)\n    y_pred=model.predict(X2_test)\n    results_d.append(mean_squared_error(y2_test, y_pred))\n","execution_count":108,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import statistics\nprint(\"Results mean\"+str(statistics.mean(results_d)))","execution_count":109,"outputs":[{"output_type":"stream","text":"Results mean42.55922526177911\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(\"Results std\"+str(statistics.stdev(results_d)))","execution_count":110,"outputs":[{"output_type":"stream","text":"Results std0.217300166043511\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"> From all the above four parts a,b,c and d, we observe that by increasing the number of layers and number of epochs, we get better standard deviation*"},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}